{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "GAN.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPOEMTwRhCpUkskGyONma7q"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "StckbXmKrQmz",
        "outputId": "6eb9778a-959a-4cbc-d572-db9f2f6a291a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cpu\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(device)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "\n",
        "class Gen(nn.Module):\n",
        "  # GAN takes an input of noise of size 10 and constructs a 7 bit number in the form of a 7 element tensor\n",
        "  def __init__(self):\n",
        "    super(Gen, self).__init__()\n",
        "    self.net = nn.Sequential(\n",
        "        nn.Linear(10,10),\n",
        "        nn.ReLU(),\n",
        "        nn.Linear(10,7),\n",
        "        nn.Sigmoid()\n",
        "    )\n",
        "  def forward(self, input):\n",
        "    return self.net(input)"
      ],
      "metadata": {
        "id": "K2bq5NmrxBp9"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Discrim(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(Discrim, self).__init__()\n",
        "    self.net = nn.Sequential(\n",
        "        #nn.Linear(7,7),\n",
        "        #nn.ReLU(),\n",
        "        nn.Linear(7,1),\n",
        "        #nn.ReLU()\n",
        "    )\n",
        "  def forward(self, input):\n",
        "    return self.net(input)"
      ],
      "metadata": {
        "id": "B8suMBDZ1FMQ"
      },
      "execution_count": 118,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "def generate_real(num):\n",
        "  inputs = [[int(x) for x in format(2*random.randint(0,63), \"07b\")] for x in range(num)]\n",
        "  \n",
        "  return torch.tensor(inputs)\n",
        "\n",
        "generate_real(20)"
      ],
      "metadata": {
        "id": "IFXN_h5_3hlw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# https://discuss.pytorch.org/t/set-constraints-on-parameters-or-layers/23620/2\n",
        "class WeightClipper(object):\n",
        "    def __init__(self, c, frequency=5):\n",
        "        self.frequency = frequency\n",
        "        self.c = abs(c)\n",
        "\n",
        "    def __call__(self, module):\n",
        "        # filter the variables to get the ones you want\n",
        "        if hasattr(module, 'weight'):\n",
        "            w = module.weight.data\n",
        "            w = w.clamp(-self.c,self.c)\n",
        "            module.weight.data = w"
      ],
      "metadata": {
        "id": "O143bJqrnXM3"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# https://agustinus.kristia.de/techblog/2017/02/04/wasserstein-gan/\n",
        "# hyperparameters from tutorial\n",
        "# reimplement training loop\n",
        "# train discrim several times, then train generator\n",
        "\n",
        "from torch import optim\n",
        "\n",
        "alpha = 0.0005 # learning rate\n",
        "c = 0.1 # clamp discriminator weights\n",
        "n_critic = 5 # number of iterations of training for discriminator\n",
        "\n",
        "generator = Gen()\n",
        "discriminator = Discrim()\n",
        "\n",
        "clipper = WeightClipper(c)\n",
        "\n",
        "one = torch.FloatTensor([1])\n",
        "m_one = torch.FloatTensor([-1])\n",
        "\n",
        "def train(num_epochs):\n",
        "    gen_optim = optim.RMSprop(generator.parameters(), lr = alpha)\n",
        "    discrim_optim = optim.RMSprop(discriminator.parameters(), lr = alpha)\n",
        "\n",
        "    for i in range(num_epochs):\n",
        "        # training discriminator\n",
        "        for j in range(n_critic):\n",
        "            noise = torch.rand(200, 10).float()\n",
        "            fake = generator.forward(noise)\n",
        "            real = generate_real(200).float()\n",
        "            fake_loss = discriminator.forward(fake.detach())\n",
        "            real_loss = discriminator.forward(real)\n",
        "            # wasserstein loss = real - fake, goal is to maximize, equivalent to minimizing negative\n",
        "            discrim_optim.zero_grad()\n",
        "            discrim_loss = -(torch.mean(real_loss, dim=0) - torch.mean(fake_loss, dim = 0))\n",
        "            discrim_loss.backward()\n",
        "            discrim_optim.step()\n",
        "            discriminator.apply(clipper)\n",
        "        # training generator\n",
        "        noise = torch.rand(200,10).float()\n",
        "        gen_optim.zero_grad()\n",
        "        gen_loss = -torch.mean(discriminator.forward(generator.forward(noise)), dim = 0)\n",
        "        gen_loss.backward()\n",
        "        gen_optim.step()\n",
        "  \n",
        "train(10000)"
      ],
      "metadata": {
        "id": "i3CqO_QSkjcS"
      },
      "execution_count": 144,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_input = torch.rand(1,10)\n",
        "print(\"random input:\", test_input.numpy())\n",
        "output = torch.flatten(generator.forward(test_input).detach()).numpy()\n",
        "print(\"output:\",output)\n",
        "total = 0\n",
        "for i in range(7):\n",
        "  total += 2**(6-i) * output[i]\n",
        "print(\"generated number:\", total)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-GwjvVoV4kXk",
        "outputId": "8aab91af-1224-41d3-9954-d519f5635981"
      },
      "execution_count": 151,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "random input: [[0.42171234 0.9290839  0.01743454 0.5376518  0.6288203  0.47541106\n",
            "  0.35840267 0.45026326 0.8602835  0.41878998]]\n",
            "output: [5.3042114e-01 4.7890449e-01 5.3126240e-01 4.5517012e-01 4.9667582e-01\n",
            " 5.0282925e-01 3.2930450e-11]\n",
            "generated number: 64.40581750873044\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "Results:\n",
        "\n",
        "\n",
        "example output:\n",
        "[5.3427917e-01 4.6246558e-01 5.0097013e-01 4.8601577e-01 4.9112451e-01 5.1165754e-01 4.5578025e-10] => 63.88\n",
        "\n",
        "first 6 entries approximately 0.5 each, last entry is 0\n",
        "\n",
        "All valid inputs are 7 bit binary numbers. First 6 entries described by Bernoulli(0.5), last entry always 0\n",
        "\n",
        "Generator learns distribution of valid inputs and converges to the expected value\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "OvbWP3Ct-X_B"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}