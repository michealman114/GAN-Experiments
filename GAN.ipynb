{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "GAN.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyP2mM4e/9qgg0e4/71JZsAm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/michealman114/GAN-Experiments/blob/main/GAN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "StckbXmKrQmz",
        "outputId": "6eb9778a-959a-4cbc-d572-db9f2f6a291a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cpu\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(device)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "things to do for GAN\n",
        "generator\n",
        "discriminator\n",
        "\n",
        "loss\n",
        "wasserstein loss\n",
        "loss for discrimnator: d(x) - d(g(r)) where x are real inputs and r is random noise fed into the generator\n",
        "\n",
        "loss for generator: d(g(r)) \n",
        "\n",
        "discriminator tries to maximize the difference between values for generated and real inputs\n",
        "\n",
        "generator tries to maximize the value of generated inputs from the discriminator\n",
        "\n",
        "\n",
        "def discrim_loss(results, labels):\n",
        "\n",
        "  parameters\n",
        "  loss = average of d(g(r)) - d(x) (negative for minimization)\n",
        "  results: batch_size * 1 tensor\n",
        "  labels: batch_size tensor of labels where 1 is real and 0 is generated\n",
        "\n",
        "  returns:\n",
        "  1 dimensional tensor containing the loss\n",
        "  real_labels = labels.view(-1, 1)\n",
        "  fake_labels = (1 - labels).view(-1,1)\n",
        "  real = torch.sum(real_labels)\n",
        "  fake = torch.sum(fake_labels)\n",
        "  #print(real_labels)\n",
        "  #print(fake_labels)\n",
        "  return torch.sum(results * fake_labels) / fake - torch.sum(results * real_labels) / real\n",
        "\n",
        "  pass\n",
        "\n",
        "def gen_loss(results, labels):\n",
        "  labels = 1 - labels\n",
        "  labels = labels.view(-1, 1)\n",
        "  gen_labels = torch.sum(labels)\n",
        "  return torch.sum(results * labels) / -gen_labels\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "mzsFdyzprTQ5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        },
        "outputId": "2f356f03-d158-4d57-cd7e-80ed4c4d2e04"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'\\nthings to do for GAN\\ngenerator\\ndiscriminator\\n\\nloss\\nwasserstein loss\\nloss for discrimnator: d(x) - d(g(r)) where x are real inputs and r is random noise fed into the generator\\n\\nloss for generator: d(g(r)) \\n\\ndiscriminator tries to maximize the difference between values for generated and real inputs\\n\\ngenerator tries to maximize the value of generated inputs from the discriminator\\n\\n\\ndef discrim_loss(results, labels):\\n\\n  parameters\\n  loss = average of d(g(r)) - d(x) (negative for minimization)\\n  results: batch_size * 1 tensor\\n  labels: batch_size tensor of labels where 1 is real and 0 is generated\\n\\n  returns:\\n  1 dimensional tensor containing the loss\\n  real_labels = labels.view(-1, 1)\\n  fake_labels = (1 - labels).view(-1,1)\\n  real = torch.sum(real_labels)\\n  fake = torch.sum(fake_labels)\\n  #print(real_labels)\\n  #print(fake_labels)\\n  return torch.sum(results * fake_labels) / fake - torch.sum(results * real_labels) / real\\n\\n  pass\\n\\ndef gen_loss(results, labels):\\n  labels = 1 - labels\\n  labels = labels.view(-1, 1)\\n  gen_labels = torch.sum(labels)\\n  return torch.sum(results * labels) / -gen_labels\\n'"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "\n",
        "class Gen(nn.Module):\n",
        "  # GAN takes an input of noise of size 10 and constructs a 7 bit number in the form of a 7 element tensor\n",
        "  def __init__(self):\n",
        "    super(Gen, self).__init__()\n",
        "    self.net = nn.Sequential(\n",
        "        nn.Linear(10,10),\n",
        "        nn.ReLU(),\n",
        "        nn.Linear(10,7),\n",
        "        nn.Sigmoid()\n",
        "    )\n",
        "  def forward(self, input):\n",
        "    return self.net(input)"
      ],
      "metadata": {
        "id": "K2bq5NmrxBp9"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Discrim(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(Discrim, self).__init__()\n",
        "    self.net = nn.Sequential(\n",
        "        nn.Linear(7,7),\n",
        "        nn.ReLU(),\n",
        "        nn.Linear(7,1),\n",
        "        nn.ReLU()\n",
        "    )\n",
        "  def forward(self, input):\n",
        "    return self.net(input)"
      ],
      "metadata": {
        "id": "B8suMBDZ1FMQ"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "def generate_real(num):\n",
        "  inputs = [[int(x) for x in format(2*random.randint(0,63), \"07b\")] for x in range(num)]\n",
        "  \n",
        "  return torch.tensor(inputs)\n",
        "\n",
        "generate_real(20)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IFXN_h5_3hlw",
        "outputId": "7a7b0a80-ea86-4e2d-e2c5-e339e37b660e"
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0, 0, 0, 0, 1, 0, 0],\n",
              "        [0, 1, 1, 1, 0, 0, 0],\n",
              "        [0, 1, 0, 1, 1, 0, 0],\n",
              "        [1, 1, 0, 0, 0, 1, 0],\n",
              "        [0, 1, 1, 1, 0, 1, 0],\n",
              "        [0, 1, 1, 0, 1, 0, 0],\n",
              "        [0, 0, 1, 0, 1, 0, 0],\n",
              "        [1, 0, 1, 0, 0, 0, 0],\n",
              "        [1, 0, 1, 0, 0, 1, 0],\n",
              "        [1, 0, 0, 1, 0, 0, 0],\n",
              "        [1, 0, 0, 1, 0, 0, 0],\n",
              "        [0, 0, 1, 1, 0, 0, 0],\n",
              "        [1, 1, 0, 0, 1, 0, 0],\n",
              "        [0, 1, 1, 1, 0, 0, 0],\n",
              "        [0, 1, 1, 0, 1, 1, 0],\n",
              "        [1, 1, 1, 0, 1, 1, 0],\n",
              "        [0, 1, 1, 0, 0, 0, 0],\n",
              "        [1, 1, 1, 1, 1, 0, 0],\n",
              "        [0, 0, 1, 1, 0, 0, 0],\n",
              "        [1, 0, 0, 0, 0, 0, 0]])"
            ]
          },
          "metadata": {},
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "from torch import optim\n",
        "from sklearn.utils import shuffle\n",
        "loss_fn = nn.BCELoss()\n",
        "\n",
        "gen1 = Gen()\n",
        "discrim1 = Discrim()\n",
        "\n",
        "def train(num_epochs = 1000):\n",
        "  gen_optim = optim.Adam(gen1.parameters(), lr = 0.001)\n",
        "  discrim_optim = optim.Adam(discrim1.parameters(), lr = 0.001)\n",
        "\n",
        "  for i in range(num_epochs):\n",
        "    noise = torch.rand(200, 10)\n",
        "    generated = gen1.forward(noise)\n",
        "    real = generate_real(200).float()\n",
        "    #data = torch.cat((generated, real)).float()\n",
        "    #print(\"data\",data.shape)\n",
        "    gen_labels = torch.zeros(200,1)\n",
        "    real_labels = torch.ones(200,1)\n",
        "    #print(\"labels\", labels.shape)\n",
        "\n",
        "    #shuffled_data, shuffled_labels = shuffle(data,labels)\n",
        "\n",
        "    #shuffled_labels = torch.flatten(shuffled_labels)\n",
        "\n",
        "    discrim_gen_out = discrim1.forward(generated)\n",
        "\n",
        "    #print(out.shape)\n",
        "\n",
        "    gen_optim.zero_grad()\n",
        "    gen_loss = -discrim_gen_out\n",
        "    gen_loss.backward()\n",
        "    gen_optim.step()\n",
        "\n",
        "    discrim_gen_out = discrim1.forward(generated.detach())\n",
        "\n",
        "    discrim_optim.zero_grad()\n",
        "    loss2 = loss_fn(discrim_gen_out, gen_labels)\n",
        "    #loss2.backward()\n",
        "\n",
        "    discrim_optim.zero_grad()\n",
        "    real_out = discrim1.forward(real)\n",
        "    loss3 = loss_fn(real_out, real_labels)\n",
        "\n",
        "    discrim_training_loss = (loss2 + loss3)/2\n",
        "    \n",
        "    discrim_training_loss.backward()\n",
        "    discrim_optim.step()\n",
        "\n",
        "    if (i%100 == 0):\n",
        "      print(i, gen_loss.item(), discrim_training_loss.item())\n",
        "    \n",
        "  \n",
        "train()\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "-XRaYWU41hdV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# https://discuss.pytorch.org/t/set-constraints-on-parameters-or-layers/23620/2\n",
        "class WeightClipper(object):\n",
        "    def __init__(self, c, frequency=5):\n",
        "        self.frequency = frequency\n",
        "        self.c = abs(c)\n",
        "\n",
        "    def __call__(self, module):\n",
        "        # filter the variables to get the ones you want\n",
        "        if hasattr(module, 'weight'):\n",
        "            w = module.weight.data\n",
        "            w = w.clamp(-self.c,self.c)\n",
        "            module.weight.data = w"
      ],
      "metadata": {
        "id": "O143bJqrnXM3"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# https://agustinus.kristia.de/techblog/2017/02/04/wasserstein-gan/\n",
        "# alpha = 0.00005, c = 0.01 (clip values of discrim), n_critic = 5\n",
        "# hyperparameters from tutorial\n",
        "# reimplement training loop\n",
        "# train discrim several times, then train generator\n",
        "\n",
        "from torch import optim\n",
        "\n",
        "alpha = 0.00005\n",
        "c = 0.01\n",
        "n_critic = 5\n",
        "\n",
        "generator = Gen()\n",
        "discriminator = Discrim()\n",
        "\n",
        "clipper = WeightClipper(c)\n",
        "\n",
        "one = torch.FloatTensor([1])\n",
        "m_one = torch.FloatTensor([-1])\n",
        "\n",
        "def train(num_epochs):\n",
        "    # alpha = 0.00005, c = 0.01 (clip values of discrim), n_critic = 5\n",
        "    gen_optim = optim.RMSprop(generator.parameters(), lr = alpha)\n",
        "    discrim_optim = optim.RMSprop(discriminator.parameters(), lr = alpha)\n",
        "\n",
        "    for i in range(num_epochs):\n",
        "        for j in range(n_critic):\n",
        "            noise = torch.rand(200, 10).float()\n",
        "            fake = generator.forward(noise)\n",
        "            real = generate_real(200).float()\n",
        "            fake_loss = discriminator.forward(fake.detach())\n",
        "            real_loss = discriminator.forward(real)\n",
        "            # real - fake\n",
        "            discrim_optim.zero_grad()\n",
        "            discrim_loss = torch.mean(real_loss, dim=0) - torch.mean(fake_loss, dim = 0)\n",
        "            #print(discrim_loss.shape)\n",
        "            discrim_loss.backward(m_one)\n",
        "            discrim_optim.step()\n",
        "            discriminator.apply(clipper)\n",
        "        # training generator\n",
        "        noise = torch.rand(200,10).float()\n",
        "        gen_optim.zero_grad()\n",
        "        gen_loss = torch.mean(discriminator.forward(generator.forward(noise)), dim = 0)\n",
        "        gen_loss.backward(one)\n",
        "        gen_optim.step()\n",
        "  \n",
        "train(10000)"
      ],
      "metadata": {
        "id": "i3CqO_QSkjcS"
      },
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_input = torch.rand(1,10)\n",
        "print(test_input.numpy())\n",
        "generator.forward(test_input)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-GwjvVoV4kXk",
        "outputId": "e082a245-d6d5-485f-8e9f-23027f28b451"
      },
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0.19349211 0.1651839  0.46215117 0.79894763 0.37445194 0.7852252\n",
            "  0.15941554 0.1212126  0.2515173  0.82409686]]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[9.9992e-01, 1.1174e-04, 1.0598e-04, 9.9992e-01, 9.9993e-01, 2.8151e-05,\n",
              "         9.9996e-01]], grad_fn=<SigmoidBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 65
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# tensor([[4.8008e-06, 9.9998e-01, 1.4812e-05, 9.9999e-01, 3.3753e-05, 1.0000e+00, 9.9998e-01]], grad_fn=<SigmoidBackward0>)"
      ],
      "metadata": {
        "id": "OvbWP3Ct-X_B"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}